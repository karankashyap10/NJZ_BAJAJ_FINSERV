import { useState } from 'react'

import './App.css'
import FileUploadSidebar from './components/organisms/fileUploadSidebar';
import ChatWindow from './components/organisms/chatWindow';
import RAGGraphModal from './components/organisms/ragGraph';

const App = () => {
  const [files, setFiles] = useState([]);
  const [messages, setMessages] = useState([]);
  const [currentMessage, setCurrentMessage] = useState('');
  const [isLoading, setIsLoading] = useState(false);
  const [isGraphModalOpen, setIsGraphModalOpen] = useState(false);
  const [isSidebarCollapsed, setIsSidebarCollapsed] = useState(false);
  const [chatHistory, setChatHistory] = useState([
    {
      id: '1',
      title: 'Research Paper Analysis',
      messageCount: 12,
      lastUpdated: new Date(Date.now() - 86400000).toISOString()
    },
    {
      id: '2',
      title: 'Financial Report Review',
      messageCount: 8,
      lastUpdated: new Date(Date.now() - 172800000).toISOString()
    }
  ]);
  const [selectedChatId, setSelectedChatId] = useState(null);

  const handleFileUpload = (newFiles) => {
    const validFiles = newFiles.filter(file =>
      file.type === 'application/pdf' ||
      file.name.endsWith('.docx')
    );
    setFiles(prev => [...prev, ...validFiles]);
  };

  const handleFileRemove = (index) => {
    setFiles(prev => prev.filter((_, i) => i !== index));
  };

  const handleSendMessage = () => {
    if (!currentMessage.trim() || files.length === 0) return;

    const userMessage = {
      content: currentMessage,
      sender: 'user',
      timestamp: new Date()
    };

    setMessages(prev => [...prev, userMessage]);
    setCurrentMessage('');
    setIsLoading(true);

    // Simulate AI response
    setTimeout(() => {
      const aiMessage = {
        content: `Based on your uploaded documents (${files.map(f => f.name).join(', ')}), I can provide the following analysis:\n\nThis is a simulated response that would normally be generated by processing the content of your PDF/DOCX files and providing relevant answers based on the retrieved context.`,
        sender: 'ai',
        timestamp: new Date()
      };
      setMessages(prev => [...prev, aiMessage]);
      setIsLoading(false);
    }, 2000);
  };

  const handleChatSelect = (chatId) => {
    setSelectedChatId(chatId);
    // In a real app, load the chat history here
  };

  const handleToggleSidebar = () => {
    setIsSidebarCollapsed(!isSidebarCollapsed);
  };

  return (
    <>
      <div className="fixed inset-0 flex w-screen h-screen bg-gray-100">
        <FileUploadSidebar
          files={files}
          onFileUpload={handleFileUpload}
          onFileRemove={handleFileRemove}
          chatHistory={chatHistory}
          onChatSelect={handleChatSelect}
          selectedChatId={selectedChatId}
          isCollapsed={isSidebarCollapsed}
          onToggleCollapse={handleToggleSidebar}
        />

        <div className="flex-1 flex flex-col min-w-0 min-h-0">
          <ChatWindow
            messages={messages}
            isLoading={isLoading}
            message={currentMessage}
            setMessage={setCurrentMessage}
            onSendMessage={handleSendMessage}
            onFileUpload={handleFileUpload}
            onShowGraph={() => setIsGraphModalOpen(true)}
            onToggleSidebar={handleToggleSidebar}
            isSidebarCollapsed={isSidebarCollapsed}
            disabled={files.length === 0}
          />
        </div>

        <RAGGraphModal
          isOpen={isGraphModalOpen}
          onClose={() => setIsGraphModalOpen(false)}
          graphData={{}}
        />
      </div>
    </>
  );
};

export default App;
